# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: kr/re/keit/Komoran.proto

from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='kr/re/keit/Komoran.proto',
  package='kr.re.keit',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=b'\n\x18kr/re/keit/Komoran.proto\x12\nkr.re.keit\"#\n\x0fTokenizeRequest\x12\x10\n\x08sentence\x18\x01 \x01(\t\"#\n\x10TokenizeResponse\x12\x0f\n\x07keyword\x18\x01 \x03(\t2R\n\x07Komoran\x12G\n\x08tokenize\x12\x1b.kr.re.keit.TokenizeRequest\x1a\x1c.kr.re.keit.TokenizeResponse\"\x00\x62\x06proto3'
)




_TOKENIZEREQUEST = _descriptor.Descriptor(
  name='TokenizeRequest',
  full_name='kr.re.keit.TokenizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='sentence', full_name='kr.re.keit.TokenizeRequest.sentence', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=40,
  serialized_end=75,
)


_TOKENIZERESPONSE = _descriptor.Descriptor(
  name='TokenizeResponse',
  full_name='kr.re.keit.TokenizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='keyword', full_name='kr.re.keit.TokenizeResponse.keyword', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=77,
  serialized_end=112,
)

DESCRIPTOR.message_types_by_name['TokenizeRequest'] = _TOKENIZEREQUEST
DESCRIPTOR.message_types_by_name['TokenizeResponse'] = _TOKENIZERESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

TokenizeRequest = _reflection.GeneratedProtocolMessageType('TokenizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZEREQUEST,
  '__module__' : 'kr.re.keit.Komoran_pb2'
  # @@protoc_insertion_point(class_scope:kr.re.keit.TokenizeRequest)
  })
_sym_db.RegisterMessage(TokenizeRequest)

TokenizeResponse = _reflection.GeneratedProtocolMessageType('TokenizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZERESPONSE,
  '__module__' : 'kr.re.keit.Komoran_pb2'
  # @@protoc_insertion_point(class_scope:kr.re.keit.TokenizeResponse)
  })
_sym_db.RegisterMessage(TokenizeResponse)



_KOMORAN = _descriptor.ServiceDescriptor(
  name='Komoran',
  full_name='kr.re.keit.Komoran',
  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=114,
  serialized_end=196,
  methods=[
  _descriptor.MethodDescriptor(
    name='tokenize',
    full_name='kr.re.keit.Komoran.tokenize',
    index=0,
    containing_service=None,
    input_type=_TOKENIZEREQUEST,
    output_type=_TOKENIZERESPONSE,
    serialized_options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_KOMORAN)

DESCRIPTOR.services_by_name['Komoran'] = _KOMORAN

# @@protoc_insertion_point(module_scope)
