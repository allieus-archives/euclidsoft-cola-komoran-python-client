# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: kr/re/keit/Komoran.proto

from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='kr/re/keit/Komoran.proto',
  package='kr.re.keit',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=b'\n\x18kr/re/keit/Komoran.proto\x12\nkr.re.keit\"\x8b\x01\n\x0fTokenizeRequest\x12\x34\n\x07\x64icType\x18\x01 \x01(\x0e\x32#.kr.re.keit.TokenizeRequest.DicType\x12\x10\n\x08sentence\x18\x02 \x01(\t\"0\n\x07\x44icType\x12\x0b\n\x07\x44\x45\x46\x41ULT\x10\x00\x12\x0b\n\x07OVERALL\x10\x01\x12\x0b\n\x07MINIMAL\x10\x02\"#\n\x10TokenizeResponse\x12\x0f\n\x07keyword\x18\x01 \x03(\t2R\n\x07Komoran\x12G\n\x08tokenize\x12\x1b.kr.re.keit.TokenizeRequest\x1a\x1c.kr.re.keit.TokenizeResponse\"\x00\x62\x06proto3'
)



_TOKENIZEREQUEST_DICTYPE = _descriptor.EnumDescriptor(
  name='DicType',
  full_name='kr.re.keit.TokenizeRequest.DicType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='DEFAULT', index=0, number=0,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='OVERALL', index=1, number=1,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MINIMAL', index=2, number=2,
      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
  serialized_start=132,
  serialized_end=180,
)
_sym_db.RegisterEnumDescriptor(_TOKENIZEREQUEST_DICTYPE)


_TOKENIZEREQUEST = _descriptor.Descriptor(
  name='TokenizeRequest',
  full_name='kr.re.keit.TokenizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='dicType', full_name='kr.re.keit.TokenizeRequest.dicType', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='sentence', full_name='kr.re.keit.TokenizeRequest.sentence', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _TOKENIZEREQUEST_DICTYPE,
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=41,
  serialized_end=180,
)


_TOKENIZERESPONSE = _descriptor.Descriptor(
  name='TokenizeResponse',
  full_name='kr.re.keit.TokenizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='keyword', full_name='kr.re.keit.TokenizeResponse.keyword', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=182,
  serialized_end=217,
)

_TOKENIZEREQUEST.fields_by_name['dicType'].enum_type = _TOKENIZEREQUEST_DICTYPE
_TOKENIZEREQUEST_DICTYPE.containing_type = _TOKENIZEREQUEST
DESCRIPTOR.message_types_by_name['TokenizeRequest'] = _TOKENIZEREQUEST
DESCRIPTOR.message_types_by_name['TokenizeResponse'] = _TOKENIZERESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

TokenizeRequest = _reflection.GeneratedProtocolMessageType('TokenizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZEREQUEST,
  '__module__' : 'kr.re.keit.Komoran_pb2'
  # @@protoc_insertion_point(class_scope:kr.re.keit.TokenizeRequest)
  })
_sym_db.RegisterMessage(TokenizeRequest)

TokenizeResponse = _reflection.GeneratedProtocolMessageType('TokenizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZERESPONSE,
  '__module__' : 'kr.re.keit.Komoran_pb2'
  # @@protoc_insertion_point(class_scope:kr.re.keit.TokenizeResponse)
  })
_sym_db.RegisterMessage(TokenizeResponse)



_KOMORAN = _descriptor.ServiceDescriptor(
  name='Komoran',
  full_name='kr.re.keit.Komoran',
  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=219,
  serialized_end=301,
  methods=[
  _descriptor.MethodDescriptor(
    name='tokenize',
    full_name='kr.re.keit.Komoran.tokenize',
    index=0,
    containing_service=None,
    input_type=_TOKENIZEREQUEST,
    output_type=_TOKENIZERESPONSE,
    serialized_options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_KOMORAN)

DESCRIPTOR.services_by_name['Komoran'] = _KOMORAN

# @@protoc_insertion_point(module_scope)
